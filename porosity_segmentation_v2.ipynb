{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpbDkzvtn17O",
        "outputId": "89fa5c68-bc23-46e3-b42b-7833ad888f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YXdBZOl2hAu"
      },
      "source": [
        "# Code to extract all images from rar files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkzJGUg0oSV-"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Destination folder where files will be extracted\n",
        "destination_folder = '/content/drive/MyDrive/Porosity DL Project/Middle'\n",
        "\n",
        "# Find all .rar files in the folder\n",
        "rar_files = glob.glob('*.rar')\n",
        "\n",
        "# Extract each .rar file\n",
        "for rar_file in rar_files:\n",
        "    print(f\"Extracting {rar_file}...\")\n",
        "    os.system(f'unrar x \"{rar_file}\" \"{destination_folder}\"')\n",
        "    print(f\"{rar_file} extracted successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioHpwtWC2ncW"
      },
      "source": [
        "# Counting number of images in the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNdsxMY4o3X_"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DFfuy1myXRz"
      },
      "source": [
        "# Copying images from Bottom and Middle to Original (Merging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW7Ut1XEy-8V",
        "outputId": "7321d134-e156-4cdc-e8f2-cb63d7d108b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in folder: 553\n"
          ]
        }
      ],
      "source": [
        "# ORIGINAL\n",
        "\n",
        "# Path to your folder (update this)\n",
        "folder_path = \"/content/drive/MyDrive/Porosity DL Project/combined\"\n",
        "\n",
        "# Define image extensions\n",
        "image_extensions = {\".tif\"}\n",
        "\n",
        "# Count images\n",
        "num_images = sum(1 for file in os.listdir(folder_path) if file.lower().endswith(tuple(image_extensions)))\n",
        "\n",
        "print(f\"Number of images in folder: {num_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BbLXKN2gnGq"
      },
      "source": [
        "# Converting to binary masks using otsu thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqtmqc0r4Ojy",
        "outputId": "55094925-37f8-46d8-9c7f-49312d31e49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All images processed and saved in: /content/drive/MyDrive/Porosity DL Project/Binary\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ------------------- Set Paths -------------------\n",
        "input_folder = \"/content/drive/MyDrive/Porosity DL Project/combined\"  # Folder containing original images\n",
        "output_folder = \"/content/drive/MyDrive/Porosity DL Project/Binary\"         # Folder to save binary masks\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# ------------------- Process All Images -------------------\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(('.tif')):  # Process only image files\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        mask_path = os.path.join(output_folder, filename)  # Save with same filename\n",
        "\n",
        "        # Load image in grayscale\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply Otsu's Thresholding\n",
        "        _, mask = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Save binary mask\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "\n",
        "        #print(f\"Processed: {filename}\")\n",
        "\n",
        "print(\"All images processed and saved in:\", output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R44BPBMSoql0",
        "outputId": "9c9e4b27-c351-4930-a633-f128f0eb9362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in folder: 553\n"
          ]
        }
      ],
      "source": [
        "# Binary\n",
        "\n",
        "# Path to your folder (update this)\n",
        "folder_path = \"/content/drive/MyDrive/Porosity DL Project/Binary\"\n",
        "\n",
        "# Define image extensions\n",
        "image_extensions = {\".tif\"}\n",
        "\n",
        "# Count images\n",
        "num_images = sum(1 for file in os.listdir(folder_path) if file.lower().endswith(tuple(image_extensions)))\n",
        "\n",
        "print(f\"Number of images in folder: {num_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMve8TCz6vMd"
      },
      "source": [
        "# U-Net Model (Defining & Compiling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B683FA3eswLq",
        "outputId": "a7850110-ba4a-417e-d2c7-96e007a2ea06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │      \u001b[38;5;34m9,438,208\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m4,096\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ batch_normalization_9… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,719,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m524,544\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m65\u001b[0m │ batch_normalization_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ batch_normalization_9… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ batch_normalization_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,054,145\u001b[0m (118.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,054,145</span> (118.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,042,369\u001b[0m (118.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,042,369</span> (118.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,776\u001b[0m (46.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,776</span> (46.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "# ------------------- Define U-Net Model -------------------\n",
        "def unet_model(input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder (Downsampling Path)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Dropout(0.5)(c5)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "\n",
        "    # Decoder (Upsampling Path)\n",
        "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# ------------------- Compile Model -------------------\n",
        "model = unet_model()\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=[binary_crossentropy], metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkA2eatH6-qk"
      },
      "source": [
        "# Load Dataset (Images + Binary Masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ondtRYh656W",
        "outputId": "8c70a765-c6eb-4de0-b9aa-1de02661ba74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data Loaded: (553, 256, 256, 1), (553, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------- Set Paths -------------------\n",
        "image_folder = \"/content/drive/MyDrive/Porosity DL Project/combined\"\n",
        "mask_folder = \"/content/drive/MyDrive/Porosity DL Project/Binary\"\n",
        "\n",
        "IMG_SIZE = 256  # Resize to 256x256\n",
        "\n",
        "# ------------------- Load Dataset -------------------\n",
        "def load_data(image_folder, mask_folder):\n",
        "    images, masks = [], []\n",
        "\n",
        "    for filename in sorted(os.listdir(image_folder)):\n",
        "        if filename.endswith(('.tif')):\n",
        "            img_path = os.path.join(image_folder, filename)\n",
        "            mask_path = os.path.join(mask_folder, filename)\n",
        "\n",
        "            # Load and preprocess image\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            img = img / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "            # Load and preprocess mask\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if mask is None:\n",
        "                print(f\"Error loading mask: {mask_path}\")\n",
        "                continue  # Skip this image if mask loading fails\n",
        "            mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
        "            mask = mask / 255.0\n",
        "            mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "X, Y = load_data(image_folder, mask_folder)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"✅ Data Loaded: {X.shape}, {Y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM0po5s_7ltH"
      },
      "source": [
        "# Training U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBfEmeMg7SPB",
        "outputId": "856c4661-0038-4991-cdfd-2bcdaf8a6f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 5s/step - accuracy: 0.8826 - loss: 0.2837 - mean_io_u: 0.3279 - val_accuracy: 0.7157 - val_loss: 0.6735 - val_mean_io_u: 0.3277\n",
            "Epoch 2/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9854 - loss: 0.0426 - mean_io_u: 0.3280 - val_accuracy: 0.6430 - val_loss: 0.6319 - val_mean_io_u: 0.3277\n",
            "Epoch 3/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9859 - loss: 0.0356 - mean_io_u: 0.3279 - val_accuracy: 0.6430 - val_loss: 0.6095 - val_mean_io_u: 0.3277\n",
            "Epoch 4/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9861 - loss: 0.0293 - mean_io_u: 0.3279 - val_accuracy: 0.6430 - val_loss: 0.5898 - val_mean_io_u: 0.3277\n",
            "Epoch 5/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9865 - loss: 0.0248 - mean_io_u: 0.3279 - val_accuracy: 0.6430 - val_loss: 0.5800 - val_mean_io_u: 0.3277\n",
            "Epoch 6/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9867 - loss: 0.0217 - mean_io_u: 0.3279 - val_accuracy: 0.6430 - val_loss: 0.5767 - val_mean_io_u: 0.3277\n",
            "Epoch 7/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9871 - loss: 0.0194 - mean_io_u: 0.3279 - val_accuracy: 0.6430 - val_loss: 0.5466 - val_mean_io_u: 0.3277\n",
            "Epoch 8/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 881ms/step - accuracy: 0.9870 - loss: 0.0184 - mean_io_u: 0.3280 - val_accuracy: 0.6430 - val_loss: 0.5944 - val_mean_io_u: 0.3277\n",
            "Epoch 9/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 894ms/step - accuracy: 0.9872 - loss: 0.0175 - mean_io_u: 0.3279 - val_accuracy: 0.6608 - val_loss: 0.4954 - val_mean_io_u: 0.3277\n",
            "Epoch 10/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 894ms/step - accuracy: 0.9872 - loss: 0.0169 - mean_io_u: 0.3281 - val_accuracy: 0.7690 - val_loss: 0.4096 - val_mean_io_u: 0.3277\n",
            "Epoch 11/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9872 - loss: 0.0164 - mean_io_u: 0.3282 - val_accuracy: 0.8141 - val_loss: 0.3184 - val_mean_io_u: 0.3277\n",
            "Epoch 12/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0160 - mean_io_u: 0.3283 - val_accuracy: 0.8617 - val_loss: 0.2313 - val_mean_io_u: 0.3277\n",
            "Epoch 13/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0157 - mean_io_u: 0.3286 - val_accuracy: 0.8982 - val_loss: 0.1928 - val_mean_io_u: 0.3277\n",
            "Epoch 14/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0153 - mean_io_u: 0.3289 - val_accuracy: 0.9344 - val_loss: 0.1279 - val_mean_io_u: 0.3277\n",
            "Epoch 15/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9872 - loss: 0.0155 - mean_io_u: 0.3296 - val_accuracy: 0.9646 - val_loss: 0.0823 - val_mean_io_u: 0.3277\n",
            "Epoch 16/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0152 - mean_io_u: 0.3302 - val_accuracy: 0.9715 - val_loss: 0.0658 - val_mean_io_u: 0.3277\n",
            "Epoch 17/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0150 - mean_io_u: 0.3310 - val_accuracy: 0.9752 - val_loss: 0.0556 - val_mean_io_u: 0.3277\n",
            "Epoch 18/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9872 - loss: 0.0148 - mean_io_u: 0.3318 - val_accuracy: 0.9784 - val_loss: 0.0502 - val_mean_io_u: 0.3277\n",
            "Epoch 19/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9872 - loss: 0.0148 - mean_io_u: 0.3332 - val_accuracy: 0.9795 - val_loss: 0.0477 - val_mean_io_u: 0.3278\n",
            "Epoch 20/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9872 - loss: 0.0146 - mean_io_u: 0.3332 - val_accuracy: 0.9811 - val_loss: 0.0443 - val_mean_io_u: 0.3346\n",
            "Epoch 21/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 897ms/step - accuracy: 0.9872 - loss: 0.0144 - mean_io_u: 0.3362 - val_accuracy: 0.9824 - val_loss: 0.0420 - val_mean_io_u: 0.4030\n",
            "Epoch 22/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0142 - mean_io_u: 0.3365 - val_accuracy: 0.9834 - val_loss: 0.0385 - val_mean_io_u: 0.4341\n",
            "Epoch 23/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 884ms/step - accuracy: 0.9873 - loss: 0.0140 - mean_io_u: 0.3378 - val_accuracy: 0.9852 - val_loss: 0.0311 - val_mean_io_u: 0.4423\n",
            "Epoch 24/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0139 - mean_io_u: 0.3394 - val_accuracy: 0.9863 - val_loss: 0.0254 - val_mean_io_u: 0.4246\n",
            "Epoch 25/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 884ms/step - accuracy: 0.9872 - loss: 0.0140 - mean_io_u: 0.3411 - val_accuracy: 0.9869 - val_loss: 0.0197 - val_mean_io_u: 0.3789\n",
            "Epoch 26/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0138 - mean_io_u: 0.3424 - val_accuracy: 0.9872 - val_loss: 0.0165 - val_mean_io_u: 0.3633\n",
            "Epoch 27/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9872 - loss: 0.0139 - mean_io_u: 0.3452 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.3464\n",
            "Epoch 28/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0135 - mean_io_u: 0.3455 - val_accuracy: 0.9874 - val_loss: 0.0146 - val_mean_io_u: 0.3527\n",
            "Epoch 29/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0135 - mean_io_u: 0.3482 - val_accuracy: 0.9874 - val_loss: 0.0141 - val_mean_io_u: 0.3521\n",
            "Epoch 30/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0136 - mean_io_u: 0.3503 - val_accuracy: 0.9875 - val_loss: 0.0135 - val_mean_io_u: 0.3470\n",
            "Epoch 31/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 894ms/step - accuracy: 0.9873 - loss: 0.0134 - mean_io_u: 0.3524 - val_accuracy: 0.9875 - val_loss: 0.0135 - val_mean_io_u: 0.3536\n",
            "Epoch 32/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0133 - mean_io_u: 0.3533 - val_accuracy: 0.9875 - val_loss: 0.0132 - val_mean_io_u: 0.3581\n",
            "Epoch 33/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 881ms/step - accuracy: 0.9873 - loss: 0.0133 - mean_io_u: 0.3569 - val_accuracy: 0.9875 - val_loss: 0.0134 - val_mean_io_u: 0.3709\n",
            "Epoch 34/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0133 - mean_io_u: 0.3589 - val_accuracy: 0.9875 - val_loss: 0.0135 - val_mean_io_u: 0.3789\n",
            "Epoch 35/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0132 - mean_io_u: 0.3604 - val_accuracy: 0.9875 - val_loss: 0.0134 - val_mean_io_u: 0.3747\n",
            "Epoch 36/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0131 - mean_io_u: 0.3633 - val_accuracy: 0.9875 - val_loss: 0.0129 - val_mean_io_u: 0.3680\n",
            "Epoch 37/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9872 - loss: 0.0131 - mean_io_u: 0.3654 - val_accuracy: 0.9875 - val_loss: 0.0131 - val_mean_io_u: 0.3773\n",
            "Epoch 38/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0130 - mean_io_u: 0.3673 - val_accuracy: 0.9875 - val_loss: 0.0133 - val_mean_io_u: 0.3907\n",
            "Epoch 39/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9873 - loss: 0.0130 - mean_io_u: 0.3693 - val_accuracy: 0.9875 - val_loss: 0.0131 - val_mean_io_u: 0.3819\n",
            "Epoch 40/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9872 - loss: 0.0130 - mean_io_u: 0.3722 - val_accuracy: 0.9875 - val_loss: 0.0130 - val_mean_io_u: 0.3851\n",
            "Epoch 41/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0129 - mean_io_u: 0.3733 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.3863\n",
            "Epoch 42/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 881ms/step - accuracy: 0.9873 - loss: 0.0128 - mean_io_u: 0.3762 - val_accuracy: 0.9875 - val_loss: 0.0129 - val_mean_io_u: 0.3928\n",
            "Epoch 43/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 881ms/step - accuracy: 0.9874 - loss: 0.0127 - mean_io_u: 0.3787 - val_accuracy: 0.9875 - val_loss: 0.0129 - val_mean_io_u: 0.3987\n",
            "Epoch 44/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9873 - loss: 0.0128 - mean_io_u: 0.3809 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.3979\n",
            "Epoch 45/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0126 - mean_io_u: 0.3828 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.3924\n",
            "Epoch 46/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9872 - loss: 0.0128 - mean_io_u: 0.3859 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.4021\n",
            "Epoch 47/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9872 - loss: 0.0127 - mean_io_u: 0.3881 - val_accuracy: 0.9875 - val_loss: 0.0127 - val_mean_io_u: 0.4046\n",
            "Epoch 48/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0125 - mean_io_u: 0.3899 - val_accuracy: 0.9875 - val_loss: 0.0125 - val_mean_io_u: 0.3802\n",
            "Epoch 49/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0125 - mean_io_u: 0.3926 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.4042\n",
            "Epoch 50/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0125 - mean_io_u: 0.3947 - val_accuracy: 0.9875 - val_loss: 0.0127 - val_mean_io_u: 0.4013\n",
            "Epoch 51/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0124 - mean_io_u: 0.3965 - val_accuracy: 0.9875 - val_loss: 0.0127 - val_mean_io_u: 0.4143\n",
            "Epoch 52/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9873 - loss: 0.0124 - mean_io_u: 0.3986 - val_accuracy: 0.9875 - val_loss: 0.0132 - val_mean_io_u: 0.4357\n",
            "Epoch 53/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9875 - loss: 0.0123 - mean_io_u: 0.4001 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4216\n",
            "Epoch 54/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9874 - loss: 0.0123 - mean_io_u: 0.4030 - val_accuracy: 0.9875 - val_loss: 0.0125 - val_mean_io_u: 0.3984\n",
            "Epoch 55/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0121 - mean_io_u: 0.4047 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4127\n",
            "Epoch 56/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0121 - mean_io_u: 0.4058 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4122\n",
            "Epoch 57/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9872 - loss: 0.0122 - mean_io_u: 0.4089 - val_accuracy: 0.9875 - val_loss: 0.0125 - val_mean_io_u: 0.4001\n",
            "Epoch 58/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 884ms/step - accuracy: 0.9873 - loss: 0.0121 - mean_io_u: 0.4114 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4205\n",
            "Epoch 59/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0120 - mean_io_u: 0.4115 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4001\n",
            "Epoch 60/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0119 - mean_io_u: 0.4142 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.4266\n",
            "Epoch 61/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0119 - mean_io_u: 0.4153 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4025\n",
            "Epoch 62/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9873 - loss: 0.0118 - mean_io_u: 0.4169 - val_accuracy: 0.9875 - val_loss: 0.0126 - val_mean_io_u: 0.4026\n",
            "Epoch 63/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 883ms/step - accuracy: 0.9874 - loss: 0.0117 - mean_io_u: 0.4194 - val_accuracy: 0.9875 - val_loss: 0.0129 - val_mean_io_u: 0.4564\n",
            "Epoch 64/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0116 - mean_io_u: 0.4208 - val_accuracy: 0.9875 - val_loss: 0.0127 - val_mean_io_u: 0.4275\n",
            "Epoch 65/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 897ms/step - accuracy: 0.9873 - loss: 0.0116 - mean_io_u: 0.4216 - val_accuracy: 0.9875 - val_loss: 0.0131 - val_mean_io_u: 0.4582\n",
            "Epoch 66/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9874 - loss: 0.0115 - mean_io_u: 0.4228 - val_accuracy: 0.9875 - val_loss: 0.0130 - val_mean_io_u: 0.4545\n",
            "Epoch 67/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0114 - mean_io_u: 0.4240 - val_accuracy: 0.9875 - val_loss: 0.0132 - val_mean_io_u: 0.4514\n",
            "Epoch 68/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0112 - mean_io_u: 0.4250 - val_accuracy: 0.9875 - val_loss: 0.0128 - val_mean_io_u: 0.4521\n",
            "Epoch 69/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0113 - mean_io_u: 0.4283 - val_accuracy: 0.9875 - val_loss: 0.0127 - val_mean_io_u: 0.4247\n",
            "Epoch 70/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 884ms/step - accuracy: 0.9873 - loss: 0.0112 - mean_io_u: 0.4298 - val_accuracy: 0.9874 - val_loss: 0.0131 - val_mean_io_u: 0.4472\n",
            "Epoch 71/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9874 - loss: 0.0110 - mean_io_u: 0.4295 - val_accuracy: 0.9875 - val_loss: 0.0131 - val_mean_io_u: 0.4610\n",
            "Epoch 72/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0109 - mean_io_u: 0.4302 - val_accuracy: 0.9874 - val_loss: 0.0135 - val_mean_io_u: 0.4490\n",
            "Epoch 73/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9874 - loss: 0.0108 - mean_io_u: 0.4312 - val_accuracy: 0.9875 - val_loss: 0.0130 - val_mean_io_u: 0.4351\n",
            "Epoch 74/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0106 - mean_io_u: 0.4319 - val_accuracy: 0.9874 - val_loss: 0.0138 - val_mean_io_u: 0.4677\n",
            "Epoch 75/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0106 - mean_io_u: 0.4329 - val_accuracy: 0.9875 - val_loss: 0.0132 - val_mean_io_u: 0.4449\n",
            "Epoch 76/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0104 - mean_io_u: 0.4342 - val_accuracy: 0.9874 - val_loss: 0.0138 - val_mean_io_u: 0.4744\n",
            "Epoch 77/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9873 - loss: 0.0103 - mean_io_u: 0.4339 - val_accuracy: 0.9874 - val_loss: 0.0132 - val_mean_io_u: 0.4332\n",
            "Epoch 78/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0104 - mean_io_u: 0.4357 - val_accuracy: 0.9874 - val_loss: 0.0133 - val_mean_io_u: 0.4495\n",
            "Epoch 79/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0103 - mean_io_u: 0.4390 - val_accuracy: 0.9874 - val_loss: 0.0137 - val_mean_io_u: 0.4585\n",
            "Epoch 80/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0100 - mean_io_u: 0.4383 - val_accuracy: 0.9874 - val_loss: 0.0136 - val_mean_io_u: 0.4505\n",
            "Epoch 81/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0100 - mean_io_u: 0.4389 - val_accuracy: 0.9874 - val_loss: 0.0142 - val_mean_io_u: 0.4853\n",
            "Epoch 82/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0099 - mean_io_u: 0.4392 - val_accuracy: 0.9874 - val_loss: 0.0138 - val_mean_io_u: 0.4474\n",
            "Epoch 83/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0098 - mean_io_u: 0.4414 - val_accuracy: 0.9874 - val_loss: 0.0137 - val_mean_io_u: 0.4490\n",
            "Epoch 84/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0098 - mean_io_u: 0.4429 - val_accuracy: 0.9874 - val_loss: 0.0137 - val_mean_io_u: 0.4416\n",
            "Epoch 85/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0096 - mean_io_u: 0.4441 - val_accuracy: 0.9874 - val_loss: 0.0136 - val_mean_io_u: 0.4279\n",
            "Epoch 86/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0097 - mean_io_u: 0.4465 - val_accuracy: 0.9874 - val_loss: 0.0142 - val_mean_io_u: 0.4751\n",
            "Epoch 87/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0093 - mean_io_u: 0.4450 - val_accuracy: 0.9874 - val_loss: 0.0139 - val_mean_io_u: 0.4435\n",
            "Epoch 88/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0094 - mean_io_u: 0.4491 - val_accuracy: 0.9874 - val_loss: 0.0149 - val_mean_io_u: 0.4993\n",
            "Epoch 89/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0092 - mean_io_u: 0.4492 - val_accuracy: 0.9874 - val_loss: 0.0142 - val_mean_io_u: 0.4604\n",
            "Epoch 90/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0091 - mean_io_u: 0.4503 - val_accuracy: 0.9874 - val_loss: 0.0146 - val_mean_io_u: 0.4727\n",
            "Epoch 91/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0091 - mean_io_u: 0.4523 - val_accuracy: 0.9874 - val_loss: 0.0146 - val_mean_io_u: 0.4736\n",
            "Epoch 92/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0092 - mean_io_u: 0.4555 - val_accuracy: 0.9874 - val_loss: 0.0140 - val_mean_io_u: 0.4373\n",
            "Epoch 93/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9875 - loss: 0.0092 - mean_io_u: 0.4576 - val_accuracy: 0.9873 - val_loss: 0.0142 - val_mean_io_u: 0.4160\n",
            "Epoch 94/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0093 - mean_io_u: 0.4640 - val_accuracy: 0.9874 - val_loss: 0.0142 - val_mean_io_u: 0.4469\n",
            "Epoch 95/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0090 - mean_io_u: 0.4614 - val_accuracy: 0.9874 - val_loss: 0.0145 - val_mean_io_u: 0.4775\n",
            "Epoch 96/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0089 - mean_io_u: 0.4631 - val_accuracy: 0.9874 - val_loss: 0.0144 - val_mean_io_u: 0.4630\n",
            "Epoch 97/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0088 - mean_io_u: 0.4635 - val_accuracy: 0.9874 - val_loss: 0.0147 - val_mean_io_u: 0.4794\n",
            "Epoch 98/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0088 - mean_io_u: 0.4664 - val_accuracy: 0.9873 - val_loss: 0.0144 - val_mean_io_u: 0.4497\n",
            "Epoch 99/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9875 - loss: 0.0087 - mean_io_u: 0.4688 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4826\n",
            "Epoch 100/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0087 - mean_io_u: 0.4706 - val_accuracy: 0.9874 - val_loss: 0.0144 - val_mean_io_u: 0.4523\n",
            "Epoch 101/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0086 - mean_io_u: 0.4722 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4865\n",
            "Epoch 102/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0085 - mean_io_u: 0.4740 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4796\n",
            "Epoch 103/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0086 - mean_io_u: 0.4769 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5052\n",
            "Epoch 104/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0085 - mean_io_u: 0.4781 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5065\n",
            "Epoch 105/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0085 - mean_io_u: 0.4799 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4800\n",
            "Epoch 106/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0085 - mean_io_u: 0.4832 - val_accuracy: 0.9874 - val_loss: 0.0150 - val_mean_io_u: 0.4954\n",
            "Epoch 107/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0085 - mean_io_u: 0.4850 - val_accuracy: 0.9874 - val_loss: 0.0149 - val_mean_io_u: 0.4980\n",
            "Epoch 108/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0086 - mean_io_u: 0.4910 - val_accuracy: 0.9874 - val_loss: 0.0146 - val_mean_io_u: 0.4689\n",
            "Epoch 109/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0085 - mean_io_u: 0.4915 - val_accuracy: 0.9873 - val_loss: 0.0145 - val_mean_io_u: 0.4658\n",
            "Epoch 110/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0084 - mean_io_u: 0.4932 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4911\n",
            "Epoch 111/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0084 - mean_io_u: 0.4945 - val_accuracy: 0.9874 - val_loss: 0.0150 - val_mean_io_u: 0.4931\n",
            "Epoch 112/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0084 - mean_io_u: 0.4974 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5133\n",
            "Epoch 113/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0084 - mean_io_u: 0.4997 - val_accuracy: 0.9874 - val_loss: 0.0151 - val_mean_io_u: 0.5023\n",
            "Epoch 114/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0083 - mean_io_u: 0.5015 - val_accuracy: 0.9874 - val_loss: 0.0149 - val_mean_io_u: 0.4961\n",
            "Epoch 115/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0083 - mean_io_u: 0.5035 - val_accuracy: 0.9874 - val_loss: 0.0150 - val_mean_io_u: 0.5116\n",
            "Epoch 116/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5076 - val_accuracy: 0.9874 - val_loss: 0.0146 - val_mean_io_u: 0.4828\n",
            "Epoch 117/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0083 - mean_io_u: 0.5087 - val_accuracy: 0.9874 - val_loss: 0.0149 - val_mean_io_u: 0.4951\n",
            "Epoch 118/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0084 - mean_io_u: 0.5134 - val_accuracy: 0.9874 - val_loss: 0.0157 - val_mean_io_u: 0.5341\n",
            "Epoch 119/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5140 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5338\n",
            "Epoch 120/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5164 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5292\n",
            "Epoch 121/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5176 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5389\n",
            "Epoch 122/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5196 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5352\n",
            "Epoch 123/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.5215 - val_accuracy: 0.9873 - val_loss: 0.0156 - val_mean_io_u: 0.4929\n",
            "Epoch 124/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0088 - mean_io_u: 0.5268 - val_accuracy: 0.9874 - val_loss: 0.0150 - val_mean_io_u: 0.5085\n",
            "Epoch 125/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5272 - val_accuracy: 0.9874 - val_loss: 0.0149 - val_mean_io_u: 0.5148\n",
            "Epoch 126/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.5296 - val_accuracy: 0.9874 - val_loss: 0.0148 - val_mean_io_u: 0.4981\n",
            "Epoch 127/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0084 - mean_io_u: 0.5315 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5364\n",
            "Epoch 128/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0083 - mean_io_u: 0.5339 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5436\n",
            "Epoch 129/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5345 - val_accuracy: 0.9874 - val_loss: 0.0151 - val_mean_io_u: 0.5175\n",
            "Epoch 130/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.5374 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5410\n",
            "Epoch 131/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5392 - val_accuracy: 0.9874 - val_loss: 0.0150 - val_mean_io_u: 0.5185\n",
            "Epoch 132/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5410 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5392\n",
            "Epoch 133/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5430 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5520\n",
            "Epoch 134/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5450 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5462\n",
            "Epoch 135/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0081 - mean_io_u: 0.5469 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.5771\n",
            "Epoch 136/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5494 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5506\n",
            "Epoch 137/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0080 - mean_io_u: 0.5518 - val_accuracy: 0.9874 - val_loss: 0.0151 - val_mean_io_u: 0.5341\n",
            "Epoch 138/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.5533 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5470\n",
            "Epoch 139/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5559 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5543\n",
            "Epoch 140/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5573 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5618\n",
            "Epoch 141/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5588 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5548\n",
            "Epoch 142/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.5613 - val_accuracy: 0.9874 - val_loss: 0.0151 - val_mean_io_u: 0.5178\n",
            "Epoch 143/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0080 - mean_io_u: 0.5637 - val_accuracy: 0.9873 - val_loss: 0.0157 - val_mean_io_u: 0.5463\n",
            "Epoch 144/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.5671 - val_accuracy: 0.9874 - val_loss: 0.0156 - val_mean_io_u: 0.5686\n",
            "Epoch 145/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0081 - mean_io_u: 0.5680 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.5906\n",
            "Epoch 146/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5697 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.5580\n",
            "Epoch 147/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5721 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5742\n",
            "Epoch 148/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.5733 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5800\n",
            "Epoch 149/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.5751 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5760\n",
            "Epoch 150/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0081 - mean_io_u: 0.5773 - val_accuracy: 0.9874 - val_loss: 0.0152 - val_mean_io_u: 0.5492\n",
            "Epoch 151/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5790 - val_accuracy: 0.9874 - val_loss: 0.0160 - val_mean_io_u: 0.5890\n",
            "Epoch 152/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5812 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.5879\n",
            "Epoch 153/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0080 - mean_io_u: 0.5830 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.5882\n",
            "Epoch 154/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5847 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.5988\n",
            "Epoch 155/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.5870 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6095\n",
            "Epoch 156/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.5878 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.5982\n",
            "Epoch 157/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0081 - mean_io_u: 0.5901 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5991\n",
            "Epoch 158/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0080 - mean_io_u: 0.5917 - val_accuracy: 0.9874 - val_loss: 0.0162 - val_mean_io_u: 0.6155\n",
            "Epoch 159/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.5935 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5953\n",
            "Epoch 160/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0081 - mean_io_u: 0.5954 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6104\n",
            "Epoch 161/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0081 - mean_io_u: 0.5963 - val_accuracy: 0.9874 - val_loss: 0.0154 - val_mean_io_u: 0.5840\n",
            "Epoch 162/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.5987 - val_accuracy: 0.9874 - val_loss: 0.0157 - val_mean_io_u: 0.6037\n",
            "Epoch 163/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.6006 - val_accuracy: 0.9874 - val_loss: 0.0160 - val_mean_io_u: 0.6121\n",
            "Epoch 164/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6021 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.6028\n",
            "Epoch 165/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6042 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6321\n",
            "Epoch 166/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6056 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.6104\n",
            "Epoch 167/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9872 - loss: 0.0079 - mean_io_u: 0.6077 - val_accuracy: 0.9874 - val_loss: 0.0157 - val_mean_io_u: 0.5952\n",
            "Epoch 168/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6093 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6097\n",
            "Epoch 169/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6111 - val_accuracy: 0.9874 - val_loss: 0.0160 - val_mean_io_u: 0.6090\n",
            "Epoch 170/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6129 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.5988\n",
            "Epoch 171/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0079 - mean_io_u: 0.6146 - val_accuracy: 0.9874 - val_loss: 0.0162 - val_mean_io_u: 0.6235\n",
            "Epoch 172/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6160 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6304\n",
            "Epoch 173/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6184 - val_accuracy: 0.9874 - val_loss: 0.0158 - val_mean_io_u: 0.6042\n",
            "Epoch 174/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6193 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.6385\n",
            "Epoch 175/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9875 - loss: 0.0078 - mean_io_u: 0.6211 - val_accuracy: 0.9874 - val_loss: 0.0162 - val_mean_io_u: 0.6101\n",
            "Epoch 176/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0079 - mean_io_u: 0.6220 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6243\n",
            "Epoch 177/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6242 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6291\n",
            "Epoch 178/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6254 - val_accuracy: 0.9874 - val_loss: 0.0155 - val_mean_io_u: 0.5864\n",
            "Epoch 179/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6270 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6227\n",
            "Epoch 180/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0079 - mean_io_u: 0.6288 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6559\n",
            "Epoch 181/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6308 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.6166\n",
            "Epoch 182/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6322 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.6655\n",
            "Epoch 183/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6337 - val_accuracy: 0.9874 - val_loss: 0.0166 - val_mean_io_u: 0.6557\n",
            "Epoch 184/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0087 - mean_io_u: 0.6298 - val_accuracy: 0.8860 - val_loss: 0.3689 - val_mean_io_u: 0.3281\n",
            "Epoch 185/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9872 - loss: 0.0123 - mean_io_u: 0.5587 - val_accuracy: 0.9831 - val_loss: 0.0303 - val_mean_io_u: 0.3784\n",
            "Epoch 186/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0115 - mean_io_u: 0.5685 - val_accuracy: 0.9875 - val_loss: 0.0132 - val_mean_io_u: 0.5406\n",
            "Epoch 187/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0096 - mean_io_u: 0.5941 - val_accuracy: 0.9874 - val_loss: 0.0179 - val_mean_io_u: 0.7207\n",
            "Epoch 188/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0084 - mean_io_u: 0.6139 - val_accuracy: 0.9874 - val_loss: 0.0183 - val_mean_io_u: 0.7367\n",
            "Epoch 189/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0081 - mean_io_u: 0.6237 - val_accuracy: 0.9873 - val_loss: 0.0192 - val_mean_io_u: 0.7576\n",
            "Epoch 190/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.6300 - val_accuracy: 0.9874 - val_loss: 0.0177 - val_mean_io_u: 0.7108\n",
            "Epoch 191/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0082 - mean_io_u: 0.6299 - val_accuracy: 0.9874 - val_loss: 0.0181 - val_mean_io_u: 0.7367\n",
            "Epoch 192/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.6356 - val_accuracy: 0.9874 - val_loss: 0.0179 - val_mean_io_u: 0.7363\n",
            "Epoch 193/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6382 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.6962\n",
            "Epoch 194/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6406 - val_accuracy: 0.9874 - val_loss: 0.0173 - val_mean_io_u: 0.7015\n",
            "Epoch 195/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6435 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6817\n",
            "Epoch 196/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6454 - val_accuracy: 0.9874 - val_loss: 0.0171 - val_mean_io_u: 0.6970\n",
            "Epoch 197/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6475 - val_accuracy: 0.9874 - val_loss: 0.0169 - val_mean_io_u: 0.6827\n",
            "Epoch 198/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6499 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6767\n",
            "Epoch 199/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.6505 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.6656\n",
            "Epoch 200/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.6517 - val_accuracy: 0.9874 - val_loss: 0.0160 - val_mean_io_u: 0.6421\n",
            "Epoch 201/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6530 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.6363\n",
            "Epoch 202/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6549 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6368\n",
            "Epoch 203/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6574 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6603\n",
            "Epoch 204/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6591 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6595\n",
            "Epoch 205/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6613 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6720\n",
            "Epoch 206/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6619 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6753\n",
            "Epoch 207/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6645 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6707\n",
            "Epoch 208/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9876 - loss: 0.0076 - mean_io_u: 0.6665 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.6941\n",
            "Epoch 209/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9875 - loss: 0.0077 - mean_io_u: 0.6673 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.6637\n",
            "Epoch 210/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.6695 - val_accuracy: 0.9874 - val_loss: 0.0174 - val_mean_io_u: 0.7097\n",
            "Epoch 211/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6713 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6834\n",
            "Epoch 212/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6737 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6546\n",
            "Epoch 213/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6734 - val_accuracy: 0.9874 - val_loss: 0.0166 - val_mean_io_u: 0.6747\n",
            "Epoch 214/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6758 - val_accuracy: 0.9874 - val_loss: 0.0159 - val_mean_io_u: 0.6498\n",
            "Epoch 215/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6743 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.7092\n",
            "Epoch 216/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.6787 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6903\n",
            "Epoch 217/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6788 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6656\n",
            "Epoch 218/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0078 - mean_io_u: 0.6812 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6937\n",
            "Epoch 219/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.6837 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6807\n",
            "Epoch 220/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.6817 - val_accuracy: 0.9874 - val_loss: 0.0161 - val_mean_io_u: 0.6600\n",
            "Epoch 221/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0079 - mean_io_u: 0.6830 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6917\n",
            "Epoch 222/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6855 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6888\n",
            "Epoch 223/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.6873 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6788\n",
            "Epoch 224/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.6882 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.6823\n",
            "Epoch 225/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6900 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.6947\n",
            "Epoch 226/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.6920 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6793\n",
            "Epoch 227/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.6920 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6794\n",
            "Epoch 228/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6935 - val_accuracy: 0.9874 - val_loss: 0.0169 - val_mean_io_u: 0.6897\n",
            "Epoch 229/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.6947 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6770\n",
            "Epoch 230/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.6961 - val_accuracy: 0.9874 - val_loss: 0.0169 - val_mean_io_u: 0.6986\n",
            "Epoch 231/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6961 - val_accuracy: 0.9874 - val_loss: 0.0169 - val_mean_io_u: 0.6949\n",
            "Epoch 232/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6962 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.6972\n",
            "Epoch 233/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.6961 - val_accuracy: 0.9874 - val_loss: 0.0166 - val_mean_io_u: 0.6872\n",
            "Epoch 234/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.6983 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.7143\n",
            "Epoch 235/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7011 - val_accuracy: 0.9874 - val_loss: 0.0169 - val_mean_io_u: 0.7127\n",
            "Epoch 236/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.7013 - val_accuracy: 0.9874 - val_loss: 0.0172 - val_mean_io_u: 0.7228\n",
            "Epoch 237/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7042 - val_accuracy: 0.9874 - val_loss: 0.0174 - val_mean_io_u: 0.7248\n",
            "Epoch 238/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7054 - val_accuracy: 0.9874 - val_loss: 0.0173 - val_mean_io_u: 0.7231\n",
            "Epoch 239/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7071 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.7035\n",
            "Epoch 240/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7081 - val_accuracy: 0.9874 - val_loss: 0.0172 - val_mean_io_u: 0.7145\n",
            "Epoch 241/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7088 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.7029\n",
            "Epoch 242/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7103 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.6864\n",
            "Epoch 243/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.7059 - val_accuracy: 0.9874 - val_loss: 0.0173 - val_mean_io_u: 0.7239\n",
            "Epoch 244/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0078 - mean_io_u: 0.7101 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.7100\n",
            "Epoch 245/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.7123 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.6852\n",
            "Epoch 246/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7130 - val_accuracy: 0.9874 - val_loss: 0.0172 - val_mean_io_u: 0.7248\n",
            "Epoch 247/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7142 - val_accuracy: 0.9874 - val_loss: 0.0168 - val_mean_io_u: 0.7090\n",
            "Epoch 248/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7159 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.7057\n",
            "Epoch 249/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7168 - val_accuracy: 0.9874 - val_loss: 0.0179 - val_mean_io_u: 0.7396\n",
            "Epoch 250/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7185 - val_accuracy: 0.9874 - val_loss: 0.0178 - val_mean_io_u: 0.7423\n",
            "Epoch 251/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7188 - val_accuracy: 0.9874 - val_loss: 0.0176 - val_mean_io_u: 0.7404\n",
            "Epoch 252/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7204 - val_accuracy: 0.9874 - val_loss: 0.0172 - val_mean_io_u: 0.7249\n",
            "Epoch 253/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7218 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.7303\n",
            "Epoch 254/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7221 - val_accuracy: 0.9874 - val_loss: 0.0181 - val_mean_io_u: 0.7548\n",
            "Epoch 255/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7227 - val_accuracy: 0.9874 - val_loss: 0.0178 - val_mean_io_u: 0.7450\n",
            "Epoch 256/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7238 - val_accuracy: 0.9874 - val_loss: 0.0172 - val_mean_io_u: 0.7328\n",
            "Epoch 257/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7242 - val_accuracy: 0.9874 - val_loss: 0.0171 - val_mean_io_u: 0.7258\n",
            "Epoch 258/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7244 - val_accuracy: 0.9874 - val_loss: 0.0173 - val_mean_io_u: 0.7313\n",
            "Epoch 259/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7262 - val_accuracy: 0.9874 - val_loss: 0.0171 - val_mean_io_u: 0.7270\n",
            "Epoch 260/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7268 - val_accuracy: 0.9875 - val_loss: 0.0171 - val_mean_io_u: 0.7335\n",
            "Epoch 261/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7288 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.7224\n",
            "Epoch 262/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7296 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.7268\n",
            "Epoch 263/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7302 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7502\n",
            "Epoch 264/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7318 - val_accuracy: 0.9875 - val_loss: 0.0170 - val_mean_io_u: 0.7241\n",
            "Epoch 265/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7321 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.7026\n",
            "Epoch 266/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7303 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7491\n",
            "Epoch 267/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7338 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7443\n",
            "Epoch 268/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7355 - val_accuracy: 0.9875 - val_loss: 0.0172 - val_mean_io_u: 0.7407\n",
            "Epoch 269/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7365 - val_accuracy: 0.9875 - val_loss: 0.0172 - val_mean_io_u: 0.7430\n",
            "Epoch 270/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7361 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7488\n",
            "Epoch 271/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7376 - val_accuracy: 0.9874 - val_loss: 0.0170 - val_mean_io_u: 0.7314\n",
            "Epoch 272/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7393 - val_accuracy: 0.9874 - val_loss: 0.0174 - val_mean_io_u: 0.7411\n",
            "Epoch 273/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7401 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7400\n",
            "Epoch 274/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7424 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7484\n",
            "Epoch 275/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7417 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7636\n",
            "Epoch 276/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7436 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7522\n",
            "Epoch 277/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7437 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7753\n",
            "Epoch 278/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7457 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7638\n",
            "Epoch 279/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7471 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7739\n",
            "Epoch 280/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7472 - val_accuracy: 0.9875 - val_loss: 0.0172 - val_mean_io_u: 0.7464\n",
            "Epoch 281/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7487 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7586\n",
            "Epoch 282/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7490 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7744\n",
            "Epoch 283/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7504 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7740\n",
            "Epoch 284/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7505 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7521\n",
            "Epoch 285/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7514 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7617\n",
            "Epoch 286/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7526 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7663\n",
            "Epoch 287/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.7545 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7433\n",
            "Epoch 288/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7534 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7491\n",
            "Epoch 289/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7541 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7610\n",
            "Epoch 290/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7534 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7507\n",
            "Epoch 291/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7554 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7471\n",
            "Epoch 292/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7540 - val_accuracy: 0.9874 - val_loss: 0.0188 - val_mean_io_u: 0.7838\n",
            "Epoch 293/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7553 - val_accuracy: 0.9874 - val_loss: 0.0167 - val_mean_io_u: 0.7357\n",
            "Epoch 294/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0078 - mean_io_u: 0.7491 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7496\n",
            "Epoch 295/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7550 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7585\n",
            "Epoch 296/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7569 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7712\n",
            "Epoch 297/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7586 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7657\n",
            "Epoch 298/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7596 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7639\n",
            "Epoch 299/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7591 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7619\n",
            "Epoch 300/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7596 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7744\n",
            "Epoch 301/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.7622 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7611\n",
            "Epoch 302/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9875 - loss: 0.0076 - mean_io_u: 0.7631 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.7807\n",
            "Epoch 303/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7647 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7641\n",
            "Epoch 304/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7653 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7671\n",
            "Epoch 305/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7665 - val_accuracy: 0.9875 - val_loss: 0.0180 - val_mean_io_u: 0.7799\n",
            "Epoch 306/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7666 - val_accuracy: 0.9874 - val_loss: 0.0164 - val_mean_io_u: 0.7062\n",
            "Epoch 307/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7618 - val_accuracy: 0.9875 - val_loss: 0.0183 - val_mean_io_u: 0.7910\n",
            "Epoch 308/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7664 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7672\n",
            "Epoch 309/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7672 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7714\n",
            "Epoch 310/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7682 - val_accuracy: 0.9875 - val_loss: 0.0183 - val_mean_io_u: 0.7838\n",
            "Epoch 311/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0078 - mean_io_u: 0.7639 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7579\n",
            "Epoch 312/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7669 - val_accuracy: 0.9874 - val_loss: 0.0181 - val_mean_io_u: 0.7808\n",
            "Epoch 313/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7666 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7587\n",
            "Epoch 314/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7679 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7753\n",
            "Epoch 315/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7698 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7673\n",
            "Epoch 316/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7708 - val_accuracy: 0.9875 - val_loss: 0.0180 - val_mean_io_u: 0.7864\n",
            "Epoch 317/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7718 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7773\n",
            "Epoch 318/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7728 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7782\n",
            "Epoch 319/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7735 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7860\n",
            "Epoch 320/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7755 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7955\n",
            "Epoch 321/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7764 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7806\n",
            "Epoch 322/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7776 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7779\n",
            "Epoch 323/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7789 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7786\n",
            "Epoch 324/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7770 - val_accuracy: 0.9875 - val_loss: 0.0174 - val_mean_io_u: 0.7630\n",
            "Epoch 325/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7783 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7896\n",
            "Epoch 326/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 895ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7803 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7744\n",
            "Epoch 327/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7810 - val_accuracy: 0.9874 - val_loss: 0.0187 - val_mean_io_u: 0.7999\n",
            "Epoch 328/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 882ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7811 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.7904\n",
            "Epoch 329/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7812 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7805\n",
            "Epoch 330/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9875 - loss: 0.0075 - mean_io_u: 0.7827 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7985\n",
            "Epoch 331/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7834 - val_accuracy: 0.9875 - val_loss: 0.0180 - val_mean_io_u: 0.7880\n",
            "Epoch 332/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7833 - val_accuracy: 0.9875 - val_loss: 0.0180 - val_mean_io_u: 0.7928\n",
            "Epoch 333/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7809 - val_accuracy: 0.9874 - val_loss: 0.0181 - val_mean_io_u: 0.7030\n",
            "Epoch 334/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7799 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7689\n",
            "Epoch 335/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7804 - val_accuracy: 0.9875 - val_loss: 0.0170 - val_mean_io_u: 0.7576\n",
            "Epoch 336/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7823 - val_accuracy: 0.9875 - val_loss: 0.0175 - val_mean_io_u: 0.7694\n",
            "Epoch 337/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7828 - val_accuracy: 0.9875 - val_loss: 0.0173 - val_mean_io_u: 0.7693\n",
            "Epoch 338/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7848 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7826\n",
            "Epoch 339/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7858 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.7904\n",
            "Epoch 340/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7870 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7853\n",
            "Epoch 341/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7884 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.7892\n",
            "Epoch 342/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7891 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7925\n",
            "Epoch 343/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7897 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7927\n",
            "Epoch 344/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7904 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8009\n",
            "Epoch 345/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7928 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8048\n",
            "Epoch 346/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.7924 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7941\n",
            "Epoch 347/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7943 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7950\n",
            "Epoch 348/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7945 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.7974\n",
            "Epoch 349/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7959 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7893\n",
            "Epoch 350/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7952 - val_accuracy: 0.9875 - val_loss: 0.0186 - val_mean_io_u: 0.8052\n",
            "Epoch 351/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0076 - mean_io_u: 0.7960 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8006\n",
            "Epoch 352/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7967 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8059\n",
            "Epoch 353/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7970 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.7996\n",
            "Epoch 354/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7972 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.7994\n",
            "Epoch 355/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7984 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8018\n",
            "Epoch 356/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 885ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7989 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8159\n",
            "Epoch 357/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7976 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8050\n",
            "Epoch 358/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7981 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.8022\n",
            "Epoch 359/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7987 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7853\n",
            "Epoch 360/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7993 - val_accuracy: 0.9875 - val_loss: 0.0171 - val_mean_io_u: 0.7680\n",
            "Epoch 361/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.7997 - val_accuracy: 0.9875 - val_loss: 0.0178 - val_mean_io_u: 0.7826\n",
            "Epoch 362/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8005 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7968\n",
            "Epoch 363/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8008 - val_accuracy: 0.9875 - val_loss: 0.0183 - val_mean_io_u: 0.7998\n",
            "Epoch 364/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8028 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.8028\n",
            "Epoch 365/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8036 - val_accuracy: 0.9875 - val_loss: 0.0176 - val_mean_io_u: 0.7879\n",
            "Epoch 366/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8029 - val_accuracy: 0.9875 - val_loss: 0.0181 - val_mean_io_u: 0.8023\n",
            "Epoch 367/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8032 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8008\n",
            "Epoch 368/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8034 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.8099\n",
            "Epoch 369/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8046 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8076\n",
            "Epoch 370/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8057 - val_accuracy: 0.9875 - val_loss: 0.0182 - val_mean_io_u: 0.8027\n",
            "Epoch 371/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8058 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8165\n",
            "Epoch 372/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8066 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8113\n",
            "Epoch 373/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8062 - val_accuracy: 0.9875 - val_loss: 0.0190 - val_mean_io_u: 0.8235\n",
            "Epoch 374/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8066 - val_accuracy: 0.9794 - val_loss: 0.0423 - val_mean_io_u: 0.5253\n",
            "Epoch 375/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0130 - mean_io_u: 0.6586 - val_accuracy: 0.9758 - val_loss: 0.0549 - val_mean_io_u: 0.3293\n",
            "Epoch 376/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0114 - mean_io_u: 0.5820 - val_accuracy: 0.9835 - val_loss: 0.0270 - val_mean_io_u: 0.4217\n",
            "Epoch 377/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0096 - mean_io_u: 0.6573 - val_accuracy: 0.9874 - val_loss: 0.0153 - val_mean_io_u: 0.6606\n",
            "Epoch 378/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0084 - mean_io_u: 0.7129 - val_accuracy: 0.9874 - val_loss: 0.0165 - val_mean_io_u: 0.7677\n",
            "Epoch 379/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.7410 - val_accuracy: 0.9874 - val_loss: 0.0183 - val_mean_io_u: 0.8338\n",
            "Epoch 380/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.7569 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8494\n",
            "Epoch 381/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.7709 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8572\n",
            "Epoch 382/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.7803 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8492\n",
            "Epoch 383/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7856 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8499\n",
            "Epoch 384/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7910 - val_accuracy: 0.9875 - val_loss: 0.0198 - val_mean_io_u: 0.8537\n",
            "Epoch 385/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.7952 - val_accuracy: 0.9875 - val_loss: 0.0196 - val_mean_io_u: 0.8472\n",
            "Epoch 386/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.7988 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8281\n",
            "Epoch 387/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8028 - val_accuracy: 0.9875 - val_loss: 0.0190 - val_mean_io_u: 0.8308\n",
            "Epoch 388/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8072 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8314\n",
            "Epoch 389/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8093 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8289\n",
            "Epoch 390/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8118 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8162\n",
            "Epoch 391/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8141 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8287\n",
            "Epoch 392/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8166 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8251\n",
            "Epoch 393/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8192 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8255\n",
            "Epoch 394/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8206 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8252\n",
            "Epoch 395/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8213 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8293\n",
            "Epoch 396/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8229 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8373\n",
            "Epoch 397/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8234 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8188\n",
            "Epoch 398/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8213 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8233\n",
            "Epoch 399/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8234 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8242\n",
            "Epoch 400/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8238 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8329\n",
            "Epoch 401/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8242 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8288\n",
            "Epoch 402/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8242 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8243\n",
            "Epoch 403/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 894ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8226 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8231\n",
            "Epoch 404/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8241 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8237\n",
            "Epoch 405/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.8221 - val_accuracy: 0.9874 - val_loss: 0.0163 - val_mean_io_u: 0.7368\n",
            "Epoch 406/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.8078 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.7845\n",
            "Epoch 407/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.8127 - val_accuracy: 0.9874 - val_loss: 0.0173 - val_mean_io_u: 0.7708\n",
            "Epoch 408/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8116 - val_accuracy: 0.9875 - val_loss: 0.0177 - val_mean_io_u: 0.7854\n",
            "Epoch 409/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8144 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8082\n",
            "Epoch 410/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8167 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8173\n",
            "Epoch 411/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8174 - val_accuracy: 0.9875 - val_loss: 0.0184 - val_mean_io_u: 0.8119\n",
            "Epoch 412/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8183 - val_accuracy: 0.9875 - val_loss: 0.0186 - val_mean_io_u: 0.8163\n",
            "Epoch 413/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8193 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8347\n",
            "Epoch 414/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0076 - mean_io_u: 0.8208 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8316\n",
            "Epoch 415/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8220 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8324\n",
            "Epoch 416/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8223 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8175\n",
            "Epoch 417/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8226 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8314\n",
            "Epoch 418/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8234 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8322\n",
            "Epoch 419/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8243 - val_accuracy: 0.9875 - val_loss: 0.0190 - val_mean_io_u: 0.8269\n",
            "Epoch 420/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8243 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8304\n",
            "Epoch 421/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8258 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8371\n",
            "Epoch 422/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8268 - val_accuracy: 0.9875 - val_loss: 0.0198 - val_mean_io_u: 0.8394\n",
            "Epoch 423/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8262 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8341\n",
            "Epoch 424/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8264 - val_accuracy: 0.9875 - val_loss: 0.0197 - val_mean_io_u: 0.8339\n",
            "Epoch 425/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8277 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8363\n",
            "Epoch 426/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0076 - mean_io_u: 0.8270 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8461\n",
            "Epoch 427/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8279 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8418\n",
            "Epoch 428/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8267 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8246\n",
            "Epoch 429/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8252 - val_accuracy: 0.9875 - val_loss: 0.0190 - val_mean_io_u: 0.8247\n",
            "Epoch 430/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8275 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8306\n",
            "Epoch 431/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8275 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8298\n",
            "Epoch 432/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8291 - val_accuracy: 0.9875 - val_loss: 0.0196 - val_mean_io_u: 0.8334\n",
            "Epoch 433/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8291 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8315\n",
            "Epoch 434/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8300 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8337\n",
            "Epoch 435/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8292 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8367\n",
            "Epoch 436/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8303 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8341\n",
            "Epoch 437/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8294 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8366\n",
            "Epoch 438/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8292 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8316\n",
            "Epoch 439/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8304 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8351\n",
            "Epoch 440/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8299 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8358\n",
            "Epoch 441/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8301 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8425\n",
            "Epoch 442/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8314 - val_accuracy: 0.9875 - val_loss: 0.0196 - val_mean_io_u: 0.8350\n",
            "Epoch 443/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8320 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8440\n",
            "Epoch 444/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9872 - loss: 0.0076 - mean_io_u: 0.8323 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8377\n",
            "Epoch 445/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8328 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8376\n",
            "Epoch 446/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8325 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8351\n",
            "Epoch 447/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9875 - loss: 0.0075 - mean_io_u: 0.8329 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8339\n",
            "Epoch 448/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8333 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8455\n",
            "Epoch 449/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8339 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8424\n",
            "Epoch 450/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8343 - val_accuracy: 0.9875 - val_loss: 0.0196 - val_mean_io_u: 0.8396\n",
            "Epoch 451/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8345 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8413\n",
            "Epoch 452/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8350 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8271\n",
            "Epoch 453/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8338 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8361\n",
            "Epoch 454/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8352 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8448\n",
            "Epoch 455/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9872 - loss: 0.0076 - mean_io_u: 0.8364 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8434\n",
            "Epoch 456/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8363 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8392\n",
            "Epoch 457/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8358 - val_accuracy: 0.9875 - val_loss: 0.0190 - val_mean_io_u: 0.8331\n",
            "Epoch 458/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9875 - loss: 0.0075 - mean_io_u: 0.8361 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8403\n",
            "Epoch 459/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8362 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8457\n",
            "Epoch 460/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8374 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8383\n",
            "Epoch 461/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8371 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8396\n",
            "Epoch 462/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8377 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8356\n",
            "Epoch 463/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8382 - val_accuracy: 0.9875 - val_loss: 0.0192 - val_mean_io_u: 0.8407\n",
            "Epoch 464/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8375 - val_accuracy: 0.9875 - val_loss: 0.0198 - val_mean_io_u: 0.8494\n",
            "Epoch 465/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8390 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8412\n",
            "Epoch 466/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8389 - val_accuracy: 0.9875 - val_loss: 0.0196 - val_mean_io_u: 0.8475\n",
            "Epoch 467/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8397 - val_accuracy: 0.9875 - val_loss: 0.0198 - val_mean_io_u: 0.8431\n",
            "Epoch 468/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8389 - val_accuracy: 0.9875 - val_loss: 0.0195 - val_mean_io_u: 0.8381\n",
            "Epoch 469/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9875 - loss: 0.0075 - mean_io_u: 0.8400 - val_accuracy: 0.9875 - val_loss: 0.0197 - val_mean_io_u: 0.8460\n",
            "Epoch 470/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8401 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8566\n",
            "Epoch 471/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8399 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8416\n",
            "Epoch 472/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8389 - val_accuracy: 0.9875 - val_loss: 0.0191 - val_mean_io_u: 0.8366\n",
            "Epoch 473/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8386 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8380\n",
            "Epoch 474/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8388 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8022\n",
            "Epoch 475/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8330 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8121\n",
            "Epoch 476/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.8338 - val_accuracy: 0.9874 - val_loss: 0.0180 - val_mean_io_u: 0.7952\n",
            "Epoch 477/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9872 - loss: 0.0077 - mean_io_u: 0.8280 - val_accuracy: 0.9875 - val_loss: 0.0179 - val_mean_io_u: 0.7869\n",
            "Epoch 478/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.8275 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8075\n",
            "Epoch 479/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9875 - loss: 0.0080 - mean_io_u: 0.8193 - val_accuracy: 0.9874 - val_loss: 0.0178 - val_mean_io_u: 0.7950\n",
            "Epoch 480/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - accuracy: 0.9873 - loss: 0.0080 - mean_io_u: 0.8230 - val_accuracy: 0.9872 - val_loss: 0.0195 - val_mean_io_u: 0.7614\n",
            "Epoch 481/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0079 - mean_io_u: 0.8212 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.7626\n",
            "Epoch 482/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.8196 - val_accuracy: 0.9874 - val_loss: 0.0175 - val_mean_io_u: 0.7773\n",
            "Epoch 483/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.8206 - val_accuracy: 0.9874 - val_loss: 0.0177 - val_mean_io_u: 0.7687\n",
            "Epoch 484/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9872 - loss: 0.0078 - mean_io_u: 0.8216 - val_accuracy: 0.9875 - val_loss: 0.0180 - val_mean_io_u: 0.7917\n",
            "Epoch 485/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0077 - mean_io_u: 0.8233 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8100\n",
            "Epoch 486/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8262 - val_accuracy: 0.9875 - val_loss: 0.0187 - val_mean_io_u: 0.8236\n",
            "Epoch 487/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8287 - val_accuracy: 0.9869 - val_loss: 0.0211 - val_mean_io_u: 0.6164\n",
            "Epoch 488/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0081 - mean_io_u: 0.8164 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8049\n",
            "Epoch 489/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 889ms/step - accuracy: 0.9873 - loss: 0.0078 - mean_io_u: 0.8212 - val_accuracy: 0.9874 - val_loss: 0.0186 - val_mean_io_u: 0.7994\n",
            "Epoch 490/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9874 - loss: 0.0077 - mean_io_u: 0.8252 - val_accuracy: 0.9875 - val_loss: 0.0183 - val_mean_io_u: 0.8033\n",
            "Epoch 491/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8277 - val_accuracy: 0.9875 - val_loss: 0.0185 - val_mean_io_u: 0.8242\n",
            "Epoch 492/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 886ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8299 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8192\n",
            "Epoch 493/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 888ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8314 - val_accuracy: 0.9875 - val_loss: 0.0188 - val_mean_io_u: 0.8232\n",
            "Epoch 494/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 890ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8332 - val_accuracy: 0.9875 - val_loss: 0.0189 - val_mean_io_u: 0.8305\n",
            "Epoch 495/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9874 - loss: 0.0076 - mean_io_u: 0.8345 - val_accuracy: 0.9875 - val_loss: 0.0193 - val_mean_io_u: 0.8376\n",
            "Epoch 496/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8366 - val_accuracy: 0.9875 - val_loss: 0.0194 - val_mean_io_u: 0.8436\n",
            "Epoch 497/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 893ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8370 - val_accuracy: 0.9875 - val_loss: 0.0200 - val_mean_io_u: 0.8474\n",
            "Epoch 498/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8392 - val_accuracy: 0.9875 - val_loss: 0.0197 - val_mean_io_u: 0.8489\n",
            "Epoch 499/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 891ms/step - accuracy: 0.9873 - loss: 0.0076 - mean_io_u: 0.8391 - val_accuracy: 0.9875 - val_loss: 0.0199 - val_mean_io_u: 0.8492\n",
            "Epoch 500/500\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 892ms/step - accuracy: 0.9874 - loss: 0.0075 - mean_io_u: 0.8398 - val_accuracy: 0.9875 - val_loss: 0.0200 - val_mean_io_u: 0.8498\n",
            "✅ Model Trained & Saved!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import MeanIoU\n",
        "\n",
        "# Compile Model with IoU Metric\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=binary_crossentropy, metrics=['accuracy', MeanIoU(num_classes=2)])\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 500\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "\n",
        "# ------------------- Save Model -------------------\n",
        "#model.save(\"unet_microstructure_segmentation.h5\")\n",
        "print(\"✅ Model Trained & Saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbQHYzEG9dFP"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrr0FeVW9jmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183cfd69-9295-4a2a-831c-c139419eea4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 515ms/step - accuracy: 0.9874 - loss: 0.0200 - mean_io_u: 0.8490\n",
            "✅ Model Performance:\n",
            "Loss: 0.0200\n",
            "Accuracy: 0.9875\n",
            "IoU (Jaccard Index): 0.8498\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Model\n",
        "loss, accuracy, iou = model.evaluate(X_val, Y_val)\n",
        "print(f\"✅ Model Performance:\")\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"IoU (Jaccard Index): {iou:.4f}\")  # IoU should be between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyX8uEBytiZ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3YXdBZOl2hAu"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}